# main.py
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings

from qdrant_client import QdrantClient

from qdrant_client.models import Distance, VectorParams, PointStruct
import os
from dotenv import load_dotenv
from qdrant_client.models import Distance, VectorParams, PointStruct, Filter

# API key yÃ¼kle
load_dotenv()

print("RAG Sistemi BaÅŸlatÄ±lÄ±yor...")

# 1. PDF YÃœKLEME
def load_pdf(file_path):
    """PDF dosyasÄ±nÄ± yÃ¼kle"""
    print(f"ğŸ“„ PDF yÃ¼kleniyor: {file_path}")
    loader = PyPDFLoader(file_path)
    documents = loader.load()
    print(f"âœ… {len(documents)} sayfa yÃ¼klendi")
    return documents

# 2. CHUNKING
def chunk_documents(documents):
    """DÃ¶kÃ¼manlarÄ± parÃ§alara bÃ¶l"""
    print("âœ‚ï¸  Chunking yapÄ±lÄ±yor...")
    
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=50,
        separators=["\n\n", "\n", ". ", " "]
    )
    
    chunks = text_splitter.split_documents(documents)
    print(f"âœ… {len(chunks)} chunk oluÅŸturuldu")
    print(f"ğŸ“ Ã–rnek chunk: {chunks[0].page_content[:100]}...")
    
    return chunks

# 3. EMBEDDING OLUÅTURMA
def create_embeddings(chunks):
    """Chunk'larÄ± embedding'e Ã§evir"""
    print("ğŸ”¢ Embedding'ler oluÅŸturuluyor...")
    
    embeddings_model = OpenAIEmbeddings(
        model="text-embedding-ada-002",
        openai_api_key=os.getenv("OPENAI_API_KEY")
    )
    
    texts = [chunk.page_content for chunk in chunks]
    embeddings = embeddings_model.embed_documents(texts)
    
    print(f"âœ… {len(embeddings)} embedding oluÅŸturuldu")
    print(f"ğŸ“ Embedding boyutu: {len(embeddings[0])}")
    
    return embeddings, texts

# 4. QDRANT'A KAYDETME
def index_to_qdrant(embeddings, texts):
    """Embedding'leri Qdrant'a kaydet"""
    print("ğŸ’¾ Qdrant'a kayÄ±t yapÄ±lÄ±yor...")
    
    client = QdrantClient(":memory:")
    collection_name = "my_documents"
    
    client.create_collection(
        collection_name=collection_name,
        vectors_config=VectorParams(
            size=1536,
            distance=Distance.COSINE
        )
    )
    
    points = []
    for idx, (embedding, text) in enumerate(zip(embeddings, texts)):
        point = PointStruct(
            id=idx,
            vector=embedding,
            payload={"text": text}
        )
        points.append(point)
    
    client.upsert(collection_name=collection_name, points=points)
    
    print(f"âœ… {len(points)} vektÃ¶r Qdrant'a kaydedildi")
    return client, collection_name

# 5. SORU SORMA
def search_similar(client, collection_name, query, top_k=3):
    """Soruya benzer chunk'larÄ± bul"""
    print(f"ğŸ” Arama yapÄ±lÄ±yor: '{query}'")
        
    embeddings_model = OpenAIEmbeddings(
        model="text-embedding-ada-002",
        openai_api_key=os.getenv("OPENAI_API_KEY")  
    )
    query_embedding = embeddings_model.embed_query(query)

    # --- KODU BURADA GÃœNCELLE ---
    query_response = client.query_points(
        collection_name=collection_name,
        query=query_embedding,
        limit=top_k
    )
    # ---------------------------
    
    # query_response nesnesinin iÃ§indeki 'points' listesini alÄ±yoruz
    results = query_response.points 
    
    print(f"âœ… {len(results)} sonuÃ§ bulundu")
    
    for idx, result in enumerate(results):
        print(f"\n--- SonuÃ§ {idx+1} (Skor: {result.score:.3f}) ---")
        # Yeni yapÄ±da payload'a doÄŸrudan eriÅŸim
        print(result.payload["text"][:200] + "...")

    return results

# MAIN
def main():
    documents = load_pdf("sample.pdf")
    chunks = chunk_documents(documents)
    embeddings, texts = create_embeddings(chunks)
    client, collection_name = index_to_qdrant(embeddings, texts)
    
    query = "Bu belge ne hakkÄ±nda?"
    results = search_similar(client, collection_name, query)
    
    print("\nâœ… RAG sistemi baÅŸarÄ±yla Ã§alÄ±ÅŸtÄ±!")

if __name__ == "__main__":
    main()
