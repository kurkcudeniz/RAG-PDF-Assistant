import os
import uvicorn
from fastapi import FastAPI
from dotenv import load_dotenv
from rank_bm25 import BM25Okapi
from sentence_transformers import CrossEncoder
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from openai import OpenAI

# 1. HAZIRLIK VE IMPORTLAR
load_dotenv()
app = FastAPI(title="Pro RAG Sistemi", description="EylÃ¼l RomanÄ± Analiz API")

# --- FONKSÄ°YONLAR (Alet Ã‡antasÄ±) ---

def load_pdf(file_path):
    print(f"ğŸ“„ PDF yÃ¼kleniyor: {file_path}")
    loader = PyPDFLoader(file_path)
    return loader.load()

def chunk_documents(documents):
    print("âœ‚ï¸ Chunking yapÄ±lÄ±yor...")
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    return text_splitter.split_documents(documents)

def create_embeddings(chunks):
    print("ğŸ”¢ Embedding'ler oluÅŸturuluyor...")
    model = OpenAIEmbeddings(model="text-embedding-ada-002")
    texts = [c.page_content for c in chunks]
    embeddings = model.embed_documents(texts)
    return embeddings, texts

def index_to_qdrant(embeddings, texts):
    print("ğŸ’¾ Qdrant'a kayÄ±t yapÄ±lÄ±yor...")
    client = QdrantClient(":memory:")
    col_name = "my_documents"
    client.create_collection(
        collection_name=col_name,
        vectors_config=VectorParams(size=1536, distance=Distance.COSINE)
    )
    points = [PointStruct(id=i, vector=e, payload={"text": t}) for i, (e, t) in enumerate(zip(embeddings, texts))]
    client.upsert(collection_name=col_name, points=points)
    return client, col_name

def search_similar(client, col_name, query, top_k=5):
    model = OpenAIEmbeddings(model="text-embedding-ada-002")
    q_emb = model.embed_query(query)
    res = client.query_points(collection_name=col_name, query=q_emb, limit=top_k)
    return res.points

def hybrid_search(client, col_name, query, chunks, top_k=5):
    print(f"ğŸš€ Hibrit arama: '{query}'")
    v_res = search_similar(client, col_name, query, top_k=top_k)
    v_texts = [r.payload["text"] for r in v_res]
    
    token_corpus = [c.page_content.lower().split() for c in chunks]
    bm25 = BM25Okapi(token_corpus)
    bm25_res = bm25.get_top_n(query.lower().split(), [c.page_content for c in chunks], n=top_k)
    
    final = list(set(v_texts) & set(bm25_res))
    for t in v_texts:
        if t not in final: final.append(t)
    return final[:top_k]

def rerank_results(query, candidates):
    print("âš–ï¸ Reranking (Cross-Encoder)...")
    model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
    scores = model.predict([[query, c] for c in candidates])
    reranked = sorted(zip(candidates, scores), key=lambda x: x[1], reverse=True)
    return [r[0] for r in reranked]

# --- SÄ°STEMÄ° AYAÄA KALDIRMA (Sadece text.pdf ile) ---

print("\nâš™ï¸ Sistem HazÄ±rlanÄ±yor...")
raw_docs = load_pdf("text.pdf") # Sadece hedef dosyan
chunks = chunk_documents(raw_docs)
embs, txts = create_embeddings(chunks)
q_client, collection = index_to_qdrant(embs, txts)

# --- API ENDPOINTS ---

@app.get("/")
def home():
    return {"mesaj": "EylÃ¼l RomanÄ± RAG API HazÄ±r!"}


@app.get("/ask")
def ask_question(query: str):
    """KullanÄ±cÄ±dan soru alÄ±r, arama yapar ve OpenAI ile cevap Ã¼retir."""
    # 1. AÅŸama: AdaylarÄ± topla (Hybrid Search)
    candidates = hybrid_search(q_client, collection, query, chunks)
    
    # 2. AÅŸama: Reranking (Hakem ile sÄ±rala)
    final_results = rerank_results(query, candidates)
    
    # 3. AÅŸama: GENERATION (GerÃ§ek RAG burasÄ±dÄ±r!)
    # BulduÄŸumuz en iyi metinleri birleÅŸtirip OpenAI'a 'Buradan bakarak cevapla' diyoruz.
    context = "\n".join(final_results[:3])
    
    # OpenAI istemcisini oluÅŸturuyoruz
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    # Yapay zekaya baÄŸlamÄ± ve soruyu gÃ¶nderiyoruz
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "Sen Mehmet Rauf'un EylÃ¼l romanÄ± konusunda uzman bir asistansÄ±n. Verilen 'BaÄŸlam' iÃ§indeki bilgileri kullanarak soruyu cevapla."},
            {"role": "user", "content": f"BaÄŸlam: {context}\n\nSoru: {query}"}
        ]
    )
    
    return {
        "sorgu": query,
        "yapay_zeka_cevabÄ±": response.choices[0].message.content, # Modelin yazdÄ±ÄŸÄ± gerÃ§ek cevap
        "dayandÄ±ÄŸÄ±_kaynaklar": final_results[:2] # KanÄ±t olarak sunduÄŸumuz paragraflar
    }

# --- SUNUCUYU ATEÅLE (SildiÄŸin KÄ±sÄ±m BurasÄ±) ---
if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
