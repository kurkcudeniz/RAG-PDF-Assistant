# main.py
from sentence_transformers import CrossEncoder
from rank_bm25 import BM25Okapi
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings

from qdrant_client import QdrantClient

from qdrant_client.models import Distance, VectorParams, PointStruct
import os
from dotenv import load_dotenv
from qdrant_client.models import Distance, VectorParams, PointStruct, Filter

# API key yÃ¼kle
load_dotenv()

print("RAG Sistemi BaÅŸlatÄ±lÄ±yor...")

# 1. PDF YÃœKLEME
def load_pdf(file_path):
    """PDF dosyasÄ±nÄ± yÃ¼kle"""
    print(f"ğŸ“„ PDF yÃ¼kleniyor: {file_path}")
    loader = PyPDFLoader(file_path)
    documents = loader.load()
    print(f"âœ… {len(documents)} sayfa yÃ¼klendi")
    return documents

# 2. CHUNKING
def chunk_documents(documents):
    """DÃ¶kÃ¼manlarÄ± parÃ§alara bÃ¶l"""
    print("âœ‚ï¸  Chunking yapÄ±lÄ±yor...")
    
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=50,
        separators=["\n\n", "\n", ". ", " "]
    )
    
    chunks = text_splitter.split_documents(documents)
    print(f"âœ… {len(chunks)} chunk oluÅŸturuldu")
    print(f"ğŸ“ Ã–rnek chunk: {chunks[0].page_content[:100]}...")
    
    return chunks

# 3. EMBEDDING OLUÅTURMA
def create_embeddings(chunks):
    """Chunk'larÄ± embedding'e Ã§evir"""
    print("ğŸ”¢ Embedding'ler oluÅŸturuluyor...")
    
    embeddings_model = OpenAIEmbeddings(
        model="text-embedding-ada-002",
        openai_api_key=os.getenv("OPENAI_API_KEY")
    )
    
    texts = [chunk.page_content for chunk in chunks]
    embeddings = embeddings_model.embed_documents(texts)
    
    print(f"âœ… {len(embeddings)} embedding oluÅŸturuldu")
    print(f"ğŸ“ Embedding boyutu: {len(embeddings[0])}")
    
    return embeddings, texts

# 4. QDRANT'A KAYDETME
def index_to_qdrant(embeddings, texts):
    """Embedding'leri Qdrant'a kaydet"""
    print("ğŸ’¾ Qdrant'a kayÄ±t yapÄ±lÄ±yor...")
    
    client = QdrantClient(":memory:")
    collection_name = "my_documents"
    
    client.create_collection(
        collection_name=collection_name,
        vectors_config=VectorParams(
            size=1536,
            distance=Distance.COSINE
        )
    )
    
    points = []
    for idx, (embedding, text) in enumerate(zip(embeddings, texts)):
        point = PointStruct(
            id=idx,
            vector=embedding,
            payload={"text": text}
        )
        points.append(point)
    
    client.upsert(collection_name=collection_name, points=points)
    
    print(f"âœ… {len(points)} vektÃ¶r Qdrant'a kaydedildi")
    return client, collection_name

# 5. SORU SORMA
def search_similar(client, collection_name, query, top_k=3):
    """Soruya benzer chunk'larÄ± bul"""
    print(f"ğŸ” Arama yapÄ±lÄ±yor: '{query}'")
        
    embeddings_model = OpenAIEmbeddings(
        model="text-embedding-ada-002",
        openai_api_key=os.getenv("OPENAI_API_KEY")  
    )
    query_embedding = embeddings_model.embed_query(query)

    # --- KODU BURADA GÃœNCELLE ---
    query_response = client.query_points(
        collection_name=collection_name,
        query=query_embedding,
        limit=top_k
    )
    # ---------------------------
    
    # query_response nesnesinin iÃ§indeki 'points' listesini alÄ±yoruz
    results = query_response.points 
    
    print(f"âœ… {len(results)} sonuÃ§ bulundu")
    
    for idx, result in enumerate(results):
        print(f"\n--- SonuÃ§ {idx+1} (Skor: {result.score:.3f}) ---")
        # Yeni yapÄ±da payload'a doÄŸrudan eriÅŸim
        print(result.payload["text"][:200] + "...")

    return results

# 6. HIBRIT ARAMA (BM25 + VEKTÃ–R) - BU BLOÄU main() ÃœSTÃœNE TAÅI
def hybrid_search(client, collection_name, query, chunks, top_k=3):
    print(f"\nğŸš€ Hibrit arama sÃ¼reci baÅŸladÄ±: '{query}'")
    
    # --- AdÄ±m A: VektÃ¶r AramasÄ± (Semantic - Anlamsal) ---
    vector_results = search_similar(client, collection_name, query, top_k=top_k)
    vector_texts = [res.payload["text"] for res in vector_results]
    
    # --- AdÄ±m B: BM25 AramasÄ± (Lexical - Kelime BazlÄ±) ---
    # Metinleri kelimelerine ayÄ±rÄ±yoruz (Tokenization)
    tokenized_corpus = [chunk.page_content.lower().split() for chunk in chunks]
    bm25 = BM25Okapi(tokenized_corpus)
    
    # Soruyu kelimelerine ayÄ±rÄ±p BM25 algoritmasÄ±na gÃ¶re en iyi sonuÃ§larÄ± alÄ±yoruz
    tokenized_query = query.lower().split()
    bm25_top_results = bm25.get_top_n(tokenized_query, [c.page_content for c in chunks], n=top_k)
    
    # --- AdÄ±m C: Skor BirleÅŸtirme (Score Fusion) ---
    # MÃ¼lakat CevabÄ±: "Hem vektÃ¶rde hem de BM25'te ortak Ã§Ä±kan sonuÃ§lara Ã¶ncelik verdim."
    final_results = []
    
    # Ã–nce iki listede de ortak olanlarÄ± ekleyelim (En kaliteli sonuÃ§lar)
    combined = list(set(vector_texts) & set(bm25_top_results))
    final_results.extend(combined)
    
    # Eksik kalan yerleri vektÃ¶r sonuÃ§larÄ±yla tamamlayalÄ±m
    for res in vector_texts:
        if res not in final_results:
            final_results.append(res)
            
    print(f"âœ… Hibrit arama tamamlandÄ±. {len(final_results[:top_k])} sonuÃ§ optimize edildi.")
    return final_results[:top_k]


# 7. RERANKING (HAKEM MODEL)
def rerank_results(query, candidates):
    print(f"âš–ï¸  Reranking uygulanÄ±yor (Cross-Encoder)...")
    
    # KÃ¼Ã§Ã¼k ve hÄ±zlÄ± bir reranker modeli yÃ¼klÃ¼yoruz
    model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
    
    # Soruyu ve her bir adayÄ± eÅŸleÅŸtiriyoruz
    pairs = [[query, cand] for cand in candidates]
    
    # SkorlarÄ± hesaplÄ±yoruz
    scores = model.predict(pairs)
    
    # Skorlara gÃ¶re adaylarÄ± yeniden sÄ±ralÄ±yoruz
    reranked = sorted(list(zip(candidates, scores)), key=lambda x: x[1], reverse=True)
    
    print("âœ… Yeniden sÄ±ralama tamamlandÄ±.")
    return [item[0] for item in reranked]

        

# MAIN
def main():
    documents = load_pdf("sample.pdf")
    chunks = chunk_documents(documents)
    embeddings, texts = create_embeddings(chunks)
    client, collection_name = index_to_qdrant(embeddings, texts)

    query = "Bu belge ne hakkÄ±nda?"
    
    # ESKÄ° SATIRI SÄ°LDÄ°K VEYA YORUMA ALDIK:
    # results = search_similar(client, collection_name, query)
    
    # YENÄ° HIBRIT MOTORU Ã‡ALIÅTIRIYORUZ:
    results = hybrid_search(client, collection_name, query, chunks)
    
    print("\nâœ… RAG sistemi HIBRIT modda baÅŸarÄ±yla Ã§alÄ±ÅŸtÄ±!")
    # ... Ã¶nceki adÄ±mlar aynÄ± ...
    
    # 1. AdaylarÄ± topla (Hybrid Search)
    candidates = hybrid_search(client, collection_name, query, chunks)
    
    # 2. AdaylarÄ± akÄ±llÄ±ca sÄ±rala (Reranking)
    final_results = rerank_results(query, candidates)
    
    print("\nğŸ† EN DOÄRU SONUÃ‡LAR (Reranked):")
    for idx, text in enumerate(final_results[:3]):
        print(f"{idx+1}. {text[:150]}...")





if __name__ == "__main__":
    main()


